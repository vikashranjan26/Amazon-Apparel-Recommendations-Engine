{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Amazon Apparel Recommendations Engine</h1>\n",
    "\n",
    "Skills: Python, text processing, image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Recommendation engine which suggests  similar products to the given product in any e-commerce websites ex. Amazon.com, myntra.com etc.\n",
    "\n",
    "Ex.Recommend similar apparel products using product descriptions and Images\n",
    "\n",
    "<tr> \n",
    "<td><img src=\"apperalrecommend.png\",width=300,height=300> </td>\n",
    "</tr>\n",
    "\n",
    "In this project I will build a recommendation engine that suggests relevant apparels to the given apparel.The recommendation engine, uses information about 1,80,000 products and  each product will have multiple features named.\n",
    "\n",
    "1.Title of the product <br> \n",
    "2.Brand of the product <br>\n",
    "3.Color of the product <br>\n",
    "4.Type of the product <br>\n",
    "5.Image of the apparel <br>\n",
    "\n",
    "Data Source: Amazon.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data(Data Understanding)\n",
    "Let’s start with importing the necessary libaries, reading the data, and analyze the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import all the necessary packages.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>author</th>\n",
       "      <th>availability</th>\n",
       "      <th>availability_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>editorial_reivew</th>\n",
       "      <th>editorial_review</th>\n",
       "      <th>formatted_price</th>\n",
       "      <th>large_image_url</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>model</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>publisher</th>\n",
       "      <th>reviews</th>\n",
       "      <th>sku</th>\n",
       "      <th>small_image_url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B016I2TS4W</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FNC7C</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minions Como Superheroes Ironman Women's O Nec...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>None</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>None</td>\n",
       "      <td>[False, https://www.amazon.com/reviews/iframe?...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Minions Como Superheroes Ironman Long Sleeve R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin author availability availability_type  brand color  \\\n",
       "0  B016I2TS4W   None         None              None  FNC7C  None   \n",
       "\n",
       "  editorial_reivew                                   editorial_review  \\\n",
       "0              NaN  Minions Como Superheroes Ironman Women's O Nec...   \n",
       "\n",
       "  formatted_price                                    large_image_url  \\\n",
       "0            None  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "  manufacturer                                   medium_image_url model  \\\n",
       "0         None  https://images-na.ssl-images-amazon.com/images...  None   \n",
       "\n",
       "  product_type_name publisher  \\\n",
       "0             SHIRT      None   \n",
       "\n",
       "                                             reviews   sku  \\\n",
       "0  [False, https://www.amazon.com/reviews/iframe?...  None   \n",
       "\n",
       "                                     small_image_url  \\\n",
       "0  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "                                               title  \n",
       "0  Minions Como Superheroes Ironman Long Sleeve R...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Load the amazon tops_fashion json file which consists of all information about the products\n",
    "data = pd.read_json('tops_fashion.json')\n",
    "\n",
    "# Success - Display the first record\n",
    "display(data.head(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points :  183138 \n",
      "Number of features/variables: 19 \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 183138 entries, 0 to 183137\n",
      "Data columns (total 19 columns):\n",
      "asin                 183138 non-null object\n",
      "author               1 non-null object\n",
      "availability         24532 non-null object\n",
      "availability_type    24559 non-null object\n",
      "brand                182987 non-null object\n",
      "color                64956 non-null object\n",
      "editorial_reivew     180380 non-null object\n",
      "editorial_review     2758 non-null object\n",
      "formatted_price      28395 non-null object\n",
      "large_image_url      183138 non-null object\n",
      "manufacturer         42899 non-null object\n",
      "medium_image_url     183138 non-null object\n",
      "model                62370 non-null object\n",
      "product_type_name    183138 non-null object\n",
      "publisher            42899 non-null object\n",
      "reviews              183138 non-null object\n",
      "sku                  363 non-null object\n",
      "small_image_url      183138 non-null object\n",
      "title                183138 non-null object\n",
      "dtypes: object(19)\n",
      "memory usage: 27.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print ('Number of data points : ', data.shape[0], \\\n",
    "       '\\nNumber of features/variables:', data.shape[1],'\\n\\n')\n",
    "\n",
    "#Checking out the datatypes of the features\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple investigation of the dataset can determine many irrlevent features in dataset such as author, availability .\n",
    "\n",
    "Of these 19 features, I am using only 7 features.\n",
    "    1. asin  ( Amazon standard identification number)\n",
    "    2. brand ( brand to which the product belongs to )\n",
    "    3. color ( Color information of apparel, it can contain many colors as   a value ex: red and black stripes ) \n",
    "    4. medium_image_url  ( url of the image )\n",
    "    5. product_type_name (type of the apperal, ex: SHIRT/TSHIRT )\n",
    "    6. title (title of the product.)\n",
    "    7. formatted_price (price of the product)\n",
    "    \n",
    "So,Let's shrink our dataset to the only following features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[['asin', 'brand', 'color', 'medium_image_url', 'product_type_name', 'title', 'formatted_price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After shrinking no of features in dataset our dataset have following fetures. Heare I am printing top 3 records of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points :  183138 \n",
      "Number of features: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B016I2TS4W</td>\n",
       "      <td>FNC7C</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Minions Como Superheroes Ironman Long Sleeve R...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01N49AI08</td>\n",
       "      <td>FIG Clothing</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FIG Clothing Womens Izo Tunic</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B01JDPCOHO</td>\n",
       "      <td>FIG Clothing</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FIG Clothing Womens Won Top</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin         brand color  \\\n",
       "0  B016I2TS4W         FNC7C  None   \n",
       "1  B01N49AI08  FIG Clothing  None   \n",
       "2  B01JDPCOHO  FIG Clothing  None   \n",
       "\n",
       "                                    medium_image_url product_type_name  \\\n",
       "0  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "1  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "2  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "\n",
       "                                               title formatted_price  \n",
       "0  Minions Como Superheroes Ironman Long Sleeve R...            None  \n",
       "1                      FIG Clothing Womens Izo Tunic            None  \n",
       "2                        FIG Clothing Womens Won Top            None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Number of data points : ', data.shape[0], \\\n",
    "       '\\nNumber of features:', data.shape[1])\n",
    "data.head(3) # prints the top 3 rows in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing various features of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Basic stats for the feature: product_type_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     183138\n",
      "unique        72\n",
      "top        SHIRT\n",
      "freq      167794\n",
      "Name: product_type_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# We have total 72 unique type of product_type_names\n",
    "print(data['product_type_name'].describe())\n",
    "\n",
    "# 91.62% (167794/183138) of the products are shirts,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, from above stats we can see that each product have their product name since count is equal to no of records in our dataset. So,there is no any missing value for this feature and there is 72 unique product name in our dataset with most frequent is shirt.<br><br>\n",
    "Here is name of the different product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SHIRT' 'SWEATER' 'APPAREL' 'OUTDOOR_RECREATION_PRODUCT'\n",
      " 'BOOKS_1973_AND_LATER' 'PANTS' 'HAT' 'SPORTING_GOODS' 'DRESS' 'UNDERWEAR'\n",
      " 'SKIRT' 'OUTERWEAR' 'BRA' 'ACCESSORY' 'ART_SUPPLIES' 'SLEEPWEAR'\n",
      " 'ORCA_SHIRT' 'HANDBAG' 'PET_SUPPLIES' 'SHOES' 'KITCHEN' 'ADULT_COSTUME'\n",
      " 'HOME_BED_AND_BATH' 'MISC_OTHER' 'BLAZER' 'HEALTH_PERSONAL_CARE'\n",
      " 'TOYS_AND_GAMES' 'SWIMWEAR' 'CONSUMER_ELECTRONICS' 'SHORTS' 'HOME'\n",
      " 'AUTO_PART' 'OFFICE_PRODUCTS' 'ETHNIC_WEAR' 'BEAUTY'\n",
      " 'INSTRUMENT_PARTS_AND_ACCESSORIES' 'POWERSPORTS_PROTECTIVE_GEAR' 'SHIRTS'\n",
      " 'ABIS_APPAREL' 'AUTO_ACCESSORY' 'NONAPPARELMISC' 'TOOLS' 'BABY_PRODUCT'\n",
      " 'SOCKSHOSIERY' 'POWERSPORTS_RIDING_SHIRT' 'EYEWEAR' 'SUIT'\n",
      " 'OUTDOOR_LIVING' 'POWERSPORTS_RIDING_JACKET' 'HARDWARE' 'SAFETY_SUPPLY'\n",
      " 'ABIS_DVD' 'VIDEO_DVD' 'GOLF_CLUB' 'MUSIC_POPULAR_VINYL'\n",
      " 'HOME_FURNITURE_AND_DECOR' 'TABLET_COMPUTER' 'GUILD_ACCESSORIES'\n",
      " 'ABIS_SPORTS' 'ART_AND_CRAFT_SUPPLY' 'BAG' 'MECHANICAL_COMPONENTS'\n",
      " 'SOUND_AND_RECORDING_EQUIPMENT' 'COMPUTER_COMPONENT' 'JEWELRY'\n",
      " 'BUILDING_MATERIAL' 'LUGGAGE' 'BABY_COSTUME' 'POWERSPORTS_VEHICLE_PART'\n",
      " 'PROFESSIONAL_HEALTHCARE' 'SEEDS_AND_PLANTS' 'WIRELESS_ACCESSORY']\n"
     ]
    }
   ],
   "source": [
    "# names of different product types\n",
    "print(data['product_type_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SHIRT', 167794),\n",
       " ('APPAREL', 3549),\n",
       " ('BOOKS_1973_AND_LATER', 3336),\n",
       " ('DRESS', 1584),\n",
       " ('SPORTING_GOODS', 1281),\n",
       " ('SWEATER', 837),\n",
       " ('OUTERWEAR', 796),\n",
       " ('OUTDOOR_RECREATION_PRODUCT', 729),\n",
       " ('ACCESSORY', 636),\n",
       " ('UNDERWEAR', 425)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the 10 most frequent product_type_names.\n",
    "product_type_count = Counter(list(data['product_type_name']))\n",
    "product_type_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Basic stats for the feature: brand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     182987\n",
      "unique     10577\n",
      "top         Zago\n",
      "freq         223\n",
      "Name: brand, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['brand'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in brand features there is missing valuse for some products(record) since count is only 182987 while total no of records is 183138.<br><br>\n",
    "So, No of missing values = 183138 - 182987 = 151.<br>\n",
    "And there is 10577 unique brand in dataset with Most frequent one is Zago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zago', 223),\n",
       " ('XQS', 222),\n",
       " ('Yayun', 215),\n",
       " ('YUNY', 198),\n",
       " ('XiaoTianXin-women clothes', 193),\n",
       " ('Generic', 192),\n",
       " ('Boohoo', 190),\n",
       " ('Alion', 188),\n",
       " ('Abetteric', 187),\n",
       " ('TheMogan', 187)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the 10 most frequent brand\n",
    "brand_count = Counter(list(data['brand']))\n",
    "brand_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Basic stats for the feature: color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     64956\n",
      "unique     7380\n",
      "top       Black\n",
      "freq      13207\n",
      "Name: color, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['color'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 64956 products have their color information.<br>\n",
    "So, No of missing values = 183138-64956 = 118182.<br>\n",
    "Only 35.4 % products have their color information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 118182),\n",
       " ('Black', 13207),\n",
       " ('White', 8616),\n",
       " ('Blue', 3570),\n",
       " ('Red', 2289),\n",
       " ('Pink', 1842),\n",
       " ('Grey', 1499),\n",
       " ('*', 1388),\n",
       " ('Green', 1258),\n",
       " ('Multi', 1203)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the 10 most frequent color\n",
    "color_count = Counter(list(data['color']))\n",
    "color_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Basic stats for the feature: formatted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      28395\n",
      "unique      3135\n",
      "top       $19.99\n",
      "freq         945\n",
      "Name: formatted_price, dtype: object\n"
     ]
    }
   ],
   "source": [
    " print(data['formatted_price'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 28,395 (15.5% of whole data) products have price information so there is lot of missing values for price feature in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 154743),\n",
       " ('$19.99', 945),\n",
       " ('$9.99', 749),\n",
       " ('$9.50', 601),\n",
       " ('$14.99', 472),\n",
       " ('$7.50', 463),\n",
       " ('$24.99', 414),\n",
       " ('$29.99', 370),\n",
       " ('$8.99', 343),\n",
       " ('$9.01', 336)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the 10 most frequent price from dataset.\n",
    "price_count = Counter(list(data['formatted_price']))\n",
    "price_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic stats for the feature: title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                183138\n",
      "unique                                               175985\n",
      "top       Nakoda Cotton Self Print Straight Kurti For Women\n",
      "freq                                                     77\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['title'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the products have a title feature in the dataset we can see with above outputs.<br>\n",
    "<br>\n",
    "Python have pickle files facilites in which we can save our data at any point of time. Since we have reduced the feature in dataset so we can save our dataset in pickle folder such that if we stuck at any point we can take directly data from pickle folder so that we don't need to repeat the all step again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/180k_apparel_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing\n",
    "\n",
    "We have seen that in our dataset some of the features have missing values so we need to preprocess the dataset such that there should not be any inconsistency in our dataset and dataset can work efficiently with algorithms.<br>\n",
    "\n",
    "### Missing value treatment.\n",
    "    There is many methods for treatment of missing values but I am going with Deletion method in which we delete all the records where any of the variable is missing, if processing power of computer is high than we can  use another methods such as mean/median/mode imputation for missing value instead of deletion method.\n",
    "   We have seen that feature price in our dataset have many missing values so we can remove all such records from our dataset which don't have price information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points After eliminating price=NULL : 28395\n"
     ]
    }
   ],
   "source": [
    "# read data from pickle file from previous stage\n",
    "data = pd.read_pickle('pickels/180k_apparel_data')\n",
    "\n",
    "# data['formatted_price'].isnull() => gives the information \n",
    "#about the dataframe row's which have null values price == None|Null\n",
    "data = data.loc[~data['formatted_price'].isnull()]\n",
    "print('Number of data points After eliminating price=NULL :', data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So our dataset have reduced to only 28K records after removing rcords which don't have price information.\n",
    "Similarly we can remove all record which don't have color information since color feature have also missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points After eliminating color=NULL : 28385\n"
     ]
    }
   ],
   "source": [
    "# data['color'].isnull() => gives the information about the dataframe row's which have null values price == None|Null\n",
    "data =data.loc[~data['color'].isnull()]\n",
    "print('Number of data points After eliminating color=NULL :', data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     I brought down the number of data points from 183K to 28K.\n",
    "I am processing only 28K points so that my computer can run this code in a reasonable amount of time. <br>\n",
    "Now I have less no of records in our dataset so I can pickle this processed dataset such that if there is any problems at any point of time I can directly take this dataset for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/28k_apparel_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate items\n",
    "Since in our dataset many features/attribtes such as titles of the products will be same since many products will have multiple sizes for thier products.<br>\n",
    "<br>\n",
    "So, let's see duplicates products for feature titles in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products that have duplicate titles = 2325\n"
     ]
    }
   ],
   "source": [
    "# read data from pickle file from previous stage\n",
    "data = pd.read_pickle('pickels/28k_apparel_data')\n",
    "\n",
    "# find number of products that have duplicate titles.\n",
    "print('Number of products that have duplicate titles =',sum(data.duplicated('title')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So,we have 2325 products which have same title but These produts are exactly same except in size (S, M,L,XL). we need to de-dupe them for better results since our recommendation is very much depends on the titles of the products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removal of products with short description: 27949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004GSI2OS</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>Onyx Black/ Stone</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Featherlite Ladies' Long Sleeve Stain Resistan...</td>\n",
       "      <td>$26.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B012YX2ZPI</td>\n",
       "      <td>HX-Kingdom Fashion T-shirts</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Women's Unique 100% Cotton T - Special Olympic...</td>\n",
       "      <td>$9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B001LOUGE4</td>\n",
       "      <td>Fitness Etc.</td>\n",
       "      <td>Black</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Ladies Cotton Tank 2x1 Ribbed Tank Top</td>\n",
       "      <td>$11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B003BSRPB0</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FeatherLite Ladies' Moisture Free Mesh Sport S...</td>\n",
       "      <td>$20.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B014ICEDNA</td>\n",
       "      <td>FNC7C</td>\n",
       "      <td>Purple</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Supernatural Chibis Sam Dean And Castiel Short...</td>\n",
       "      <td>$7.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          asin                        brand              color  \\\n",
       "4   B004GSI2OS                  FeatherLite  Onyx Black/ Stone   \n",
       "6   B012YX2ZPI  HX-Kingdom Fashion T-shirts              White   \n",
       "11  B001LOUGE4                 Fitness Etc.              Black   \n",
       "15  B003BSRPB0                  FeatherLite              White   \n",
       "21  B014ICEDNA                        FNC7C             Purple   \n",
       "\n",
       "                                     medium_image_url product_type_name  \\\n",
       "4   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "6   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "11  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "15  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "21  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "\n",
       "                                                title formatted_price  \n",
       "4   Featherlite Ladies' Long Sleeve Stain Resistan...          $26.26  \n",
       "6   Women's Unique 100% Cotton T - Special Olympic...           $9.99  \n",
       "11             Ladies Cotton Tank 2x1 Ribbed Tank Top          $11.99  \n",
       "15  FeatherLite Ladies' Moisture Free Mesh Sport S...          $20.54  \n",
       "21  Supernatural Chibis Sam Dean And Castiel Short...           $7.50  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove All products with very few words in title\n",
    "data_sorted = data[data['title'].apply(lambda x: len(x.split())>4)]\n",
    "print(\"After removal of products with short description:\", data_sorted.shape[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the whole dataset based on title (alphabetical order of title) such that it is easy to understand the dataset and also easy for deduping the similar products from dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61973</th>\n",
       "      <td>B06Y1KZ2WB</td>\n",
       "      <td>Éclair</td>\n",
       "      <td>Black/Pink</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Éclair Women's Printed Thin Strap Blouse Black...</td>\n",
       "      <td>$24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133820</th>\n",
       "      <td>B010RV33VE</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>Pink</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Womens Sleeveless Loose Long T-shirts...</td>\n",
       "      <td>$18.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81461</th>\n",
       "      <td>B01DDSDLNS</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Women's White Long Sleeve Single Brea...</td>\n",
       "      <td>$21.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75995</th>\n",
       "      <td>B00X5LYO9Y</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>Red Anchors</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Stripes Tank Patch/Bear Sleeve Anchor...</td>\n",
       "      <td>$15.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151570</th>\n",
       "      <td>B00WPJG35K</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Sleeve Sheer Loose Tassel Kimono Woma...</td>\n",
       "      <td>$14.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin     brand        color  \\\n",
       "61973   B06Y1KZ2WB    Éclair   Black/Pink   \n",
       "133820  B010RV33VE  xiaoming         Pink   \n",
       "81461   B01DDSDLNS  xiaoming        White   \n",
       "75995   B00X5LYO9Y  xiaoming  Red Anchors   \n",
       "151570  B00WPJG35K  xiaoming        White   \n",
       "\n",
       "                                         medium_image_url product_type_name  \\\n",
       "61973   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "133820  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "81461   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "75995   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "151570  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "\n",
       "                                                    title formatted_price  \n",
       "61973   Éclair Women's Printed Thin Strap Blouse Black...          $24.99  \n",
       "133820  xiaoming Womens Sleeveless Loose Long T-shirts...          $18.19  \n",
       "81461   xiaoming Women's White Long Sleeve Single Brea...          $21.58  \n",
       "75995   xiaoming Stripes Tank Patch/Bear Sleeve Anchor...          $15.91  \n",
       "151570  xiaoming Sleeve Sheer Loose Tassel Kimono Woma...          $14.32  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_sorted.sort_values('title',inplace=True, ascending=False)\n",
    "data_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some examples of dupliacte titles that differ only in the last few words.\n",
    "\n",
    "<pre>\n",
    "Titles 1:\n",
    "16. woman's place is in the house and the senate shirts for Womens XXL White\n",
    "17. woman's place is in the house and the senate shirts for Womens M Grey\n",
    "\n",
    "Title 2:\n",
    "25. tokidoki The Queen of Diamonds Women's Shirt X-Large\n",
    "26. tokidoki The Queen of Diamonds Women's Shirt Small\n",
    "27. tokidoki The Queen of Diamonds Women's Shirt Large\n",
    "\n",
    "Title 3:\n",
    "61. psychedelic colorful Howling Galaxy Wolf T-shirt/Colorful Rainbow Animal Print Head Shirt for woman Neon Wolf t-shirt\n",
    "62. psychedelic colorful Howling Galaxy Wolf T-shirt/Colorful Rainbow Animal Print Head Shirt for woman Neon Wolf t-shirt\n",
    "63. psychedelic colorful Howling Galaxy Wolf T-shirt/Colorful Rainbow Animal Print Head Shirt for woman Neon Wolf t-shirt\n",
    "64. psychedelic colorful Howling Galaxy Wolf T-shirt/Colorful Rainbow Animal Print Head Shirt for woman Neon Wolf t-shirt\n",
    "</pre>\n",
    "\n",
    "So, Remove all these kinds of titles if the title is almost similar. I am assuming the same titles if it is only differ by 2 words in the titles of the products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i,row in data_sorted.iterrows():\n",
    "    indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "stage1_dedupe_asins = []\n",
    "i = 0\n",
    "j = 0\n",
    "num_data_points = data_sorted.shape[0]\n",
    "while i < num_data_points and j < num_data_points:\n",
    "    \n",
    "    previous_i = i\n",
    "\n",
    "    # store the list of words of ith string in a, ex: a = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
    "    a = data['title'].loc[indices[i]].split()\n",
    "\n",
    "    # search for the similar products sequentially \n",
    "    j = i+1\n",
    "    while j < num_data_points:\n",
    "\n",
    "        # store the list of words of jth string in b, ex: b = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'Small']\n",
    "        b = data['title'].loc[indices[j]].split()\n",
    "\n",
    "        # store the maximum length of two strings\n",
    "        length = max(len(a), len(b))\n",
    "\n",
    "        # count is used to store the number of words that are matched in both strings\n",
    "        count  = 0\n",
    "\n",
    "        # itertools.zip_longest(a,b): will map the corresponding words in both strings, it will appened None in case of unequal strings\n",
    "        # example: a =['a', 'b', 'c', 'd']\n",
    "        # b = ['a', 'b', 'd']\n",
    "        # itertools.zip_longest(a,b): will give [('a','a'), ('b','b'), ('c','d'), ('d', None)]\n",
    "        for k in itertools.zip_longest(a,b): \n",
    "            if (k[0] == k[1]):\n",
    "                count += 1\n",
    "\n",
    "        # if the number of words in which both strings differ are > 2 , I am considering it as those two apperals are different\n",
    "        # if the number of words in which both strings differ are < 2 ,  I am considering it as those two apperals are same, hence I am ignoring them\n",
    "        if (length - count) > 2: # number of words in which both sensences differ\n",
    "            # if both strings are differ by more than 2 words I am including the 1st string index\n",
    "            stage1_dedupe_asins.append(data_sorted['asin'].loc[indices[i]])\n",
    "\n",
    "            # if the comaprision between num_data_points and num_data_points-1 strings and they differ in more than 2 words than include both\n",
    "            if j == num_data_points-1: stage1_dedupe_asins.append(data_sorted['asin'].loc[indices[j]])\n",
    "\n",
    "            # start searching for similar apperals corresponds 2nd string\n",
    "            i = j\n",
    "            break\n",
    "        else:\n",
    "            j += 1\n",
    "    if previous_i == i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reduce the dataset with only those products which have the same asins in the deduped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points :  17593\n"
     ]
    }
   ],
   "source": [
    "data = data.loc[data['asin'].isin(stage1_dedupe_asins)]\n",
    "print('Number of data points : ', data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data points in our dataset is reduced to only 17K so save this dataset in pickels file folder such that we can use this file directly if any difficulties comes during the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/17k_apperal_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<pre>\n",
    "\n",
    "In the previous stage, I sorted whole data in alphabetical order of  titles.Then, I removed titles which are  adjacent and very similar title(if prefixes of titles are same), I used above algorithm for removing similar products that's only because of time complextity of the code, since in next stage of the algorithm will take O(n^2) of time complextity to find similar products in entire dataset.\n",
    "\n",
    "But there are some products whose titles are not adjacent but very similar.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Titles-1\n",
    "86261.  UltraClub Women's Classic Wrinkle-Free Long Sleeve Oxford Shirt, Pink, XX-Large\n",
    "115042. UltraClub Ladies Classic Wrinkle-Free Long-Sleeve Oxford Light Blue XXL\n",
    "\n",
    "TItles-2\n",
    "75004.  EVALY Women's Cool University Of UTAH 3/4 Sleeve Raglan Tee\n",
    "109225. EVALY Women's Unique University Of UTAH 3/4 Sleeve Raglan Tees\n",
    "120832. EVALY Women's New University Of UTAH 3/4-Sleeve Raglan Tshirt\n",
    "\n",
    "</pre>\n",
    "\n",
    "So,I need to apply another algorithm/method to remove all those similar products which are not adjacent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code snippet takes significant amount of time.\n",
    "# O(n^2) time.\n",
    "# Takes about an hour to run on a decent computer.\n",
    "\n",
    "indices = []\n",
    "for i,row in data.iterrows():\n",
    "    indices.append(i)\n",
    "\n",
    "stage2_dedupe_asins = []\n",
    "while len(indices)!=0:\n",
    "    i = indices.pop()\n",
    "    stage2_dedupe_asins.append(data['asin'].loc[i])\n",
    "    # consider the first apperal's title\n",
    "    a = data['title'].loc[i].split()\n",
    "    # store the list of words of ith string in a, ex: a = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
    "    for j in indices:\n",
    "        \n",
    "        b = data['title'].loc[j].split()\n",
    "        # store the list of words of jth string in b, ex: b = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
    "        \n",
    "        length = max(len(a),len(b))\n",
    "        \n",
    "        # count is used to store the number of words that are matched in both strings\n",
    "        count  = 0\n",
    "\n",
    "        # itertools.zip_longest(a,b): will map the corresponding words in both strings, it will appened None in case of unequal strings\n",
    "        # example: a =['a', 'b', 'c', 'd']\n",
    "        # b = ['a', 'b', 'd']\n",
    "        # itertools.zip_longest(a,b): will give [('a','a'), ('b','b'), ('c','d'), ('d', None)]\n",
    "        for k in itertools.zip_longest(a,b): \n",
    "            if (k[0]==k[1]):\n",
    "                count += 1\n",
    "\n",
    "        # if the number of words in which both strings differ are < 3 , I am considering it as those two apperals are same, hence we are ignoring them\n",
    "        if (length - count) < 3:\n",
    "            indices.remove(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reduce the dataset with only those products which have the same asins in the deduped dataset in previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points after stage two of dedupe:  16435\n"
     ]
    }
   ],
   "source": [
    "data = data.loc[data['asin'].isin(stage2_dedupe_asins)]\n",
    "print('Number of data points after stage two of dedupe: ',data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from 17k apperals it reduced to 16k apperals so save it in pickel file folder such that we can use it at any point of time directly this processsed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/16k_apperal_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
